# Sentinel - Project Documentation

> **Developer-First Local LLM Tracing, Replay & Debugging System**
> 
> Current Version: **v0.1.0** | Status: **MVP Complete**

---

## ğŸ“Š Development Stage

Based on the original roadmap, we are at **~Phase 5-6 Complete**:

| Phase | Description | Status |
|-------|-------------|--------|
| Phase 0 | Design Lock | âœ… Complete |
| Phase 1 | SDK Core | âœ… Complete |
| Phase 2 | Runtime Adapters | âœ… Complete (OpenAI + Gemini) |
| Phase 3 | FastAPI Server | âœ… Complete |
| Phase 4 | Replay Engine | âœ… Complete |
| Phase 5 | CLI | âœ… Complete |
| Phase 6 | UI | âœ… Complete |
| Phase 7 | Integration & Polish | ğŸ”„ In Progress |

---

## ğŸ¯ Current Capabilities

### âœ… SDK (Python Package)

**Trace Capture Layer**
- Function decorator `@trace` for automatic tracing
- Context manager for manual control
- Explicit `CaptureLayer` class for full control

**Adapters (LLM Providers)**
| Provider | Status | Models Tested |
|----------|--------|---------------|
| OpenAI | âœ… Full Support | GPT-4, GPT-4o-mini |
| Google Gemini | âœ… Full Support | Gemini 2.5 Flash |
| Llama.cpp | ğŸ”§ Stub Ready | - |

**Trace Schema**
- Immutable, JSON-serializable traces
- Full request/response capture
- Token usage tracking
- Latency measurement
- Replay lineage tracking

---

### âœ… Server (FastAPI)

**API Endpoints**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/v1/traces` | GET | List all traces with filtering |
| `/v1/traces/{id}` | GET | Get specific trace details |
| `/v1/traces` | POST | Create a new trace |
| `/v1/traces/{id}` | DELETE | Delete a trace |
| `/v1/traces/{id}/lineage` | GET | Get replay lineage chain |
| `/v1/replay/{id}` | POST | Replay a trace |
| `/v1/replay/{id}/preview` | GET | Preview replay without executing |
| `/v1/chat/completions` | POST | OpenAI-compatible endpoint |
| `/health` | GET | Health check |
| `/docs` | GET | Swagger API documentation |

**Storage**
- JSON file-based storage (primary)
- Organized by date (`~/.sentinel/traces/YYYY-MM-DD/`)
- SQLite index (optional, for fast queries)

---

### âœ… CLI (Command Line Interface)

```bash
sentinel init          # Initialize configuration
sentinel server        # Start the server
sentinel list          # List recent traces
sentinel show <id>     # Show trace details
sentinel replay <id>   # Replay a trace
```

---

### âœ… Web UI (Trace Inspector)

- **Trace List**: View all captured traces with metadata
- **Detail View**: Full request/response inspection
- **Replay Button**: Re-execute traces with one click
- **Real-time Updates**: Refresh to see new traces
- **Dark Theme**: Modern, developer-friendly design

Access at: `http://127.0.0.1:8000/ui`

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Application Code      â”‚
â”‚  (Your Python/LangChain)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ @trace decorator
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SDK Capture Layer       â”‚  â† Intercepts LLM calls
â”‚   - OpenAI Adapter        â”‚
â”‚   - Gemini Adapter        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ HTTP / SDK
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI Server          â”‚  â† Stores & serves traces
â”‚   - REST API              â”‚
â”‚   - Replay Engine         â”‚
â”‚   - File Storage          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI                  â”‚  â† Visual inspection
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
sentinel_v0/
â”œâ”€â”€ sdk/                    # Python SDK
â”‚   â”œâ”€â”€ schema.py           # Trace schema (Pydantic)
â”‚   â”œâ”€â”€ capture.py          # Core capture layer
â”‚   â”œâ”€â”€ decorator.py        # @trace decorator
â”‚   â””â”€â”€ adapters/           # Provider adapters
â”‚       â”œâ”€â”€ openai.py       # OpenAI integration
â”‚       â”œâ”€â”€ gemini.py       # Google Gemini integration
â”‚       â””â”€â”€ llama.py        # Llama.cpp stub
â”œâ”€â”€ server/                 # FastAPI backend
â”‚   â”œâ”€â”€ main.py             # App entry point
â”‚   â”œâ”€â”€ routes/             # API endpoints
â”‚   â”‚   â”œâ”€â”€ traces.py       # CRUD operations
â”‚   â”‚   â”œâ”€â”€ replay.py       # Replay engine
â”‚   â”‚   â””â”€â”€ chat.py         # OpenAI-compatible
â”‚   â””â”€â”€ storage/            # Persistence
â”‚       â”œâ”€â”€ files.py        # JSON storage
â”‚       â””â”€â”€ sqlite.py       # SQLite index
â”œâ”€â”€ cli/                    # Command line
â”‚   â””â”€â”€ main.py             # CLI commands
â”œâ”€â”€ ui/                     # Web interface
â”‚   â”œâ”€â”€ index.html          # Trace inspector
â”‚   â””â”€â”€ app.js              # UI logic
â”œâ”€â”€ examples/               # Example scripts
â”‚   â”œâ”€â”€ test_openai_call.py
â”‚   â””â”€â”€ test_gemini_call.py
â””â”€â”€ tests/                  # Test suite
    â””â”€â”€ test_schema.py
```

---

## ğŸš€ Quick Start

```bash
# 1. Activate environment
.\sentinel\Scripts\activate

# 2. Set API keys
$env:GOOGLE_API_KEY = "your-key"
$env:OPENAI_API_KEY = "your-key"  # Optional

# 3. Start server
python -m uvicorn server.main:app --reload

# 4. Open UI
# http://127.0.0.1:8000/ui

# 5. Run a test
python examples\test_gemini_call.py
```

---

## ğŸ”® What's Next (Phase 7+)

| Feature | Priority | Status |
|---------|----------|--------|
| LangChain integration example | High | Planned |
| Diff view for replay comparison | Medium | Planned |
| Export traces to JSON/CSV | Medium | Planned |
| Streaming response support | Medium | Planned |
| More adapters (Anthropic, Cohere) | Low | Planned |
| PyPI package publishing | High | Planned |

---

## ğŸ“ Key Design Decisions

1. **Local-First**: All data stays on your machine
2. **Zero Infrastructure**: JSON + SQLite, no external services
3. **Provider Agnostic**: Works with any LLM via adapters
4. **Immutable Traces**: Once created, traces never change
5. **Replay Lineage**: Track the history of replayed traces
6. **OpenAI Compatible**: Drop-in replacement for OpenAI base URL

---

## ğŸ¤ Usage Example

```python
from sdk.adapters.gemini import GeminiAdapter

# Create adapter (auto-traces all calls)
adapter = GeminiAdapter(api_key="your-key")

# Make a call - automatically captured!
response, trace = adapter.chat_completion(
    model="gemini-2.5-flash",
    messages=[{"role": "user", "content": "Hello!"}]
)

print(f"Response: {response.text}")
print(f"Trace ID: {trace.trace_id}")
print(f"Latency: {trace.response.latency_ms}ms")
```

---

*Last Updated: 2026-01-17*
